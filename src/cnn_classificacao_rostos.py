# -*- coding: utf-8 -*-
"""CNN_Classificação_Rostos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lMZUL7ZNZQOrGYlqtA1XfaoLyxOsIdL4
"""

# 1. Instalação e importação
!pip install scikit-learn tensorflow opencv-python matplotlib pillow pillow-heif --quiet
import os, cv2, numpy as np, matplotlib.pyplot as plt, itertools
from google.colab import drive, files
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from scipy.spatial.distance import cdist

# 2. Montar Google Drive e carregar imagens

drive.mount('/content/drive')
base_dir = '/content/drive/MyDrive/fotos_rostos'
IMG_SIZE = (96, 128)  # largura, altura
classes = sorted([d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))])
print('Classes detectadas:', classes)

def preprocess_image(img_path):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, IMG_SIZE)
    img = cv2.GaussianBlur(img, (3,3), 0)
    img = img / 255.0
    return img

X, y = [], []
for label in classes:
    folder = os.path.join(base_dir, label)
    for fname in os.listdir(folder):
        if fname.lower().endswith(('.jpg','.jpeg','.png')):
            img = preprocess_image(os.path.join(folder, fname))
            X.append(img)
            y.append(label)
X = np.array(X)
y = np.array(y)
print('Total imagens:', X.shape[0])

# 3. Split estratificado entre treino e teste antes do augmentation

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)
print('Treino:', X_train.shape, 'Teste:', X_test.shape)

# 4. Data augmentation 5x no treino somente

datagen = ImageDataGenerator(
    rotation_range=10, width_shift_range=0.1, height_shift_range=0.1,
    brightness_range=[0.8,1.2], shear_range=5, zoom_range=0.1,
    horizontal_flip=True, fill_mode='nearest'
)
Xtr_aug, ytr_aug = [], []
for i in range(len(X_train)):
    img_exp = np.expand_dims(X_train[i], 0)
    lbl = y_train[i]
    Xtr_aug.append(X_train[i]); ytr_aug.append(lbl)  # original mantida
    count = 0
    for batch in datagen.flow(img_exp, batch_size=1):
        Xtr_aug.append(batch[0])
        ytr_aug.append(lbl)
        count += 1
        if count == 5:
            break
Xtr_aug = np.array(Xtr_aug)
ytr_aug = np.array(ytr_aug)
print('Treino após augmentation:', Xtr_aug.shape)

# 5. Construir e treinar a CNN

def build_model(num_classes):
    inputs = Input(shape=(IMG_SIZE[1], IMG_SIZE[0], 3))
    x = Conv2D(32, (3,3), activation='relu')(inputs)
    x = MaxPooling2D(2,2)(x)
    x = Conv2D(64, (3,3), activation='relu')(x)
    x = MaxPooling2D(2,2)(x)
    x = Conv2D(128, (3,3), activation='relu')(x)
    x = MaxPooling2D(2,2)(x)
    x = Flatten()(x)
    # Um vetor de 128 características numéricas (um embedding de 128 dimensões).
    # Esses valores não são pontos geométricos literais na face, mas sim features aprendidas automaticamente pelo rede neural durante o treinamento.
    embeddings = Dense(128, activation='relu', name='embedding')(x)
    x = Dropout(0.4)(embeddings)
    outputs = Dense(num_classes, activation='softmax')(x)
    return Model(inputs, outputs)

model = build_model(len(classes))
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(
    Xtr_aug,
    to_categorical([classes.index(lbl) for lbl in ytr_aug], num_classes=len(classes)),
    epochs=15, batch_size=32, validation_split=0.15
)
embedding_model = Model(model.input, model.get_layer('embedding').output)

# 6. Extrair embeddings de treino/teste, aplicar PCA, treinar KNN

feats_tr = embedding_model.predict(Xtr_aug, verbose=1)
feats_te = embedding_model.predict(X_test, verbose=1)
pca = PCA(n_components=32)
feats_tr_pca = pca.fit_transform(feats_tr)
feats_te_pca = pca.transform(feats_te)
knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')
knn.fit(feats_tr_pca, ytr_aug)
y_test_pred = knn.predict(feats_te_pca)

feats_te_pca = pca.transform(feats_te)
print(len(feats_te_pca))

# 7. Upload das imagens do "desconhecido" (César) para avaliação open set
uploaded = files.upload()  # opcional
X_new, y_new, min_dists = [], [], []
for fname in uploaded.keys():
    img = preprocess_image(fname)
    X_new.append(img)
    y_new.append("César")
X_new = np.array(X_new) if X_new else np.empty((0, IMG_SIZE[1], IMG_SIZE[0], 3))
if X_new.size > 0:
    feats_new = embedding_model.predict(X_new, verbose=1)
    feats_new_pca = pca.transform(feats_new)
    pred_final, min_dists = [], []
    for i in range(len(feats_new_pca)):
        dists = cdist([feats_new_pca[i]], feats_tr_pca, 'euclidean')[0]
        min_dist = dists.min()
        min_dists.append(min_dist)
        pred = knn.predict([feats_new_pca[i]])[0]
        threshold = 6.0  # Calibre com métodos empíricos
        pred_final.append("César" if min_dist > threshold else pred)
else:
    pred_final = []

# 8. Avaliação: matriz de confusão (base + desconhecido se houver)
labels_eval = list(classes) + (["César"] if pred_final else [])
y_true_all = np.concatenate([y_test, np.array(y_new)]) if pred_final else y_test
y_pred_all = np.concatenate([y_test_pred, np.array(pred_final)]) if pred_final else y_test_pred
cm = confusion_matrix(y_true_all, y_pred_all, labels=labels_eval)
accuracy = accuracy_score(y_true_all, y_pred_all)
print(f"\n{'='*50}")
print(f"Acurácia total no teste: {accuracy*100:.2f}%")
print(f"{'='*50}")

def plot_confusion_matrix(cm, labels_eval):
    plt.figure(figsize=(9,7))
    plt.imshow(cm, cmap='Blues')
    plt.title(f"Matriz de Confusão {len(labels_eval)}x{len(labels_eval)}")
    plt.xlabel("Predito")
    plt.ylabel("Verdadeiro")
    plt.xticks(np.arange(len(labels_eval)), labels_eval, rotation=45)
    plt.yticks(np.arange(len(labels_eval)), labels_eval)
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j], ha='center', va='center', color='red')
    plt.colorbar()
    plt.tight_layout()
    plt.show()
plot_confusion_matrix(cm, labels_eval)
print(classification_report(y_true_all, y_pred_all, target_names=labels_eval))

# Gráfico por classe corrigido
import numpy as np
yt_np, yp_np = np.array(y_true_all), np.array(y_pred_all)
class_acc = []
for cls in labels_eval:
    mask = (yt_np == cls)
    acc_cls = np.mean(yp_np[mask] == cls) if mask.sum() else 0.
    class_acc.append(acc_cls)
plt.figure(figsize=(10,6))
plt.bar(labels_eval, class_acc)
plt.ylabel('Acurácia por Classe')
plt.title('Performance Individual de Cada Classe')
plt.xticks(rotation=45)
for i, v in enumerate(class_acc):
    plt.text(i, v + 0.01, f'{v*100:.1f}%', ha='center')
plt.ylim(0, 1.05)
plt.show()

import plotly.graph_objects as go
import numpy as np
from sklearn.decomposition import PCA

# Projeção PCA 3D dos embeddings
pca3 = PCA(n_components=3, random_state=42)
feats_tr_pca3 = pca3.fit_transform(feats_tr)

# Garante array de rótulos
classes_list = list(class_to_color)  # nomes das pessoas

fig = go.Figure()

for nome, cor in class_to_color.items():
    mask = (ytr_arr == nome)
    fig.add_trace(go.Scatter3d(
        x=feats_tr_pca3[mask, 0],
        y=feats_tr_pca3[mask, 1],
        z=feats_tr_pca3[mask, 2],
        mode='markers',
        marker=dict(size=5, color=cor, opacity=0.78),
        name=nome,            # Nome que aparece na legenda
        showlegend=True      # Garante legenda para este grupo
    ))

fig.update_layout(
    title='Embeddings (PCA 3D) - legenda por pessoa',
    scene=dict(xaxis_title='PC1', yaxis_title='PC2', zaxis_title='PC3'),
    legend=dict(title='Pessoa', x=1, y=0.5, xanchor='left'),
    height=700,
    width=950
)
fig.show()

import numpy as np

# Escolha uma imagem amostra para testar (por exemplo, a primeira do conjunto de teste)
indice_amostra = 0
imagem_amostra = X_test[indice_amostra:indice_amostra+1]  # deve ser um batch com shape (1, H, W, C)

# Gere o embedding usando o modelo de extração
embedding_vetor = embedding_model.predict(imagem_amostra)

# embedding_vetor terá shape (1, 128); extraímos o vetor 1D com [0]
embedding_vetor = embedding_vetor[0]

# Imprime o vetor de 128 valores
print("Embedding da imagem amostra (128 dimensões):")
print(embedding_vetor)

# (Opcional) Para imprimir de forma mais legível, formate os valores
for i, val in enumerate(embedding_vetor):
    print(f"Dim {i+1}: {val:.4f}")

# @title
# === CÉLULA: SALVAR MODELO KERAS NO GOOGLE DRIVE ===
# Salva:
#  - model.keras (modelo principal)
#  - embedding_model.keras (se existir)
#  - classes.json (lista de classes/pessoas)
#  em /content/drive/MyDrive/CNN_Classificacao_Rostos/modelos/<timestamp>/

import os, time, json, pathlib

# 1) Montar o Google Drive (Colab)
try:
    from google.colab import drive  # já importado no notebook, mas seguro repetir
    drive.mount('/content/drive', force_remount=False)
    print("Drive montado em /content/drive")
except Exception as e:
    print("Aviso: monte o Drive manualmente se estiver fora do Colab:", e)

# 2) Pasta de saída com versionamento (timestamp)
STAMP = time.strftime("%Y%m%d-%H%M%S")
BASE_DIR = "/content/drive/MyDrive/CNN_Classificacao_Rostos/modelos"
OUT_DIR = os.path.join(BASE_DIR, f"modelo_{STAMP}")
os.makedirs(OUT_DIR, exist_ok=True)

# 3) Salvar modelos Keras
try:
    import tensorflow as tf
except Exception as e:
    raise RuntimeError("TensorFlow/Keras não disponível no ambiente.") from e

saved = []

# Salvar o modelo principal (variável 'model' usada no notebook)
if 'model' in globals() and isinstance(globals()['model'], tf.keras.Model):
    model_path = os.path.join(OUT_DIR, "model.keras")
    globals()['model'].save(model_path)
    saved.append(model_path)
    print(f"[OK] Modelo salvo: {model_path}")
else:
    print("Aviso: variável 'model' não encontrada como tf.keras.Model.")

# Salvar o modelo de embeddings, se existir
if 'embedding_model' in globals() and isinstance(globals()['embedding_model'], tf.keras.Model):
    emb_path = os.path.join(OUT_DIR, "embedding_model.keras")
    globals()['embedding_model'].save(emb_path)
    saved.append(emb_path)
    print(f"[OK] Embeddings salvos: {emb_path}")
else:
    print("Obs: 'embedding_model' não encontrado; pulando.")

# 4) Salvar metadados: classes (lista de pessoas)
meta = {}
if 'classes' in globals():
    try:
        meta['classes'] = list(globals()['classes'])
    except Exception:
        pass

# 5) Persistir metadados
try:
    with open(os.path.join(OUT_DIR, "classes.json"), "w", encoding="utf-8") as f:
        json.dump(meta.get('classes', []), f, ensure_ascii=False, indent=2)
        print(f"[OK] classes.json salvo em {OUT_DIR}/classes.json")
except Exception as e:
    print("Aviso: falha ao salvar classes.json:", e)

# (Opcional) salvar histórico, se você tiver guardado o retorno do model.fit como 'history'
if 'history' in globals():
    try:
        with open(os.path.join(OUT_DIR, "history.json"), "w", encoding="utf-8") as f:
            json.dump(getattr(globals()['history'], 'history', {}), f, ensure_ascii=False, indent=2)
            print(f"[OK] history.json salvo em {OUT_DIR}/history.json")
    except Exception as e:
        print("Obs: não foi possível salvar history.json:", e)

# 6) Listar conteúdo salvo
print("\nArquivos salvos em:", OUT_DIR)
for p in sorted(pathlib.Path(OUT_DIR).glob("*")):
    print(" -", p.name)